{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Notebook for model development\n","This notebook should be used to develop the model submodules locally. Note, that model relevant changes have to be made in the model subclasses. Additional code in this document is only used to get a better understanding of the dataflow and debug some outputs."]},{"cell_type":"markdown","metadata":{},"source":["## 1: Set up environment\n","### Install dependencies\n","This will use the automation `install_dependencies.sh` in order to install necessary packages. Additional packages for development can be installed afterwards."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! cd .. && bash automation/train_model/install_dependencies.sh"]},{"cell_type":"markdown","metadata":{},"source":["### Import packages"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import gc"]},{"cell_type":"markdown","metadata":{},"source":["## 2: Get the data ready\n","In this step, the data will be imported and preprocessed.\n","\n","### Download Dataset\n","The dataset has to be imported using the submodule `model/import_data.py`."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from model.import_dataset import import_dataset\n","\n","dataset_id = \"ea93eb20-616c-4ad2-9d82-cca701766612\"\n","images, labels, uids = import_dataset(dataset_id)\n","\n","del dataset_id\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["### Inspect dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Number of images: \", images.shape[0])\n","print(\"Labels from \", np.min(labels), \" to \", np.max(labels), \"\\n\")\n","\n","def plot_image(image, label):\n","  plt.imshow(image)\n","  plt.title(f'distance={label}')\n","  plt.show()\n","\n","# Plot some images\n","num_images_to_plot = 1\n","for i in range(0, num_images_to_plot):\n","  plot_image(images[i], labels[i])\n","\n","# Plot histogram of labels\n","plt.hist(labels, edgecolor='black')  # Erstelle das Histogramm mit 10 Bins\n","plt.title('Distribution of labels in dataset')\n","plt.xlabel('Distance [mm]')\n","plt.ylabel('n')\n","plt.show()\n","\n","del num_images_to_plot, i\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocess dataset\n","The dataset is preprocessed using the submodule `model/preprocess_data.py`."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from model.preprocess_data import preprocess_data\n","\n","test_split = 0.2\n","random_state = 0\n","train_x, train_y, train_uids, test_x, test_y, test_uids = \\\n","    preprocess_data(images, labels, uids, test_split, random_state)\n","\n","del images, labels, uids\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\nTrainingsdaten: \")\n","mean = np.mean(train_x)\n","std = np.std(train_x)\n","max = np.max(train_x)\n","min = np.min(train_x)\n","print(f\"Anzahl: {train_x.shape[0]}\")\n","print(f\"Durchschnittlicher Pixelwert: {mean:.2f}\")\n","print(f\"Standardabweichung der Pixelwerte: {std:.2f}\")\n","print(f\"Höchster Pixelwert: {max:.2f}\")\n","print(f\"Niedrigster Pixelwert: {min:.2f}\")\n","print(f\"Bildgröße (Höhe x Breite): {train_x.shape[1]} x {train_x.shape[2]}\")\n","print(f\"Anzahl der Klassen: {len(np.unique(train_y))}\")\n","\n","plot_image(train_x[0], train_y[0])\n","\n","print(\"\\nTestdaten: \")\n","mean = np.mean(test_x)\n","std = np.std(test_x)\n","max = np.max(test_x)\n","min = np.min(test_x)\n","print(f\"Anzahl: {test_x.shape[0]}\")\n","print(f\"Durchschnittlicher Pixelwert: {mean:.2f}\")\n","print(f\"Standardabweichung der Pixelwerte: {std:.2f}\")\n","print(f\"Höchster Pixelwert: {max:.2f}\")\n","print(f\"Niedrigster Pixelwert: {min:.2f}\")\n","print(f\"Bildgröße (Höhe x Breite): {test_x.shape[1]} x {test_x.shape[2]}\")\n","print(f\"Anzahl der Klassen: {len(np.unique(test_y))}\")\n","\n","plot_image(test_x[0], test_y[0])\n","\n","# Plot histogram of labels\n","print(\"\\nLabel distribution in training and test set:\")\n","plt.hist([train_y, test_y], label=['Train', 'Test'],\n","          edgecolor='black', color=['blue', 'orange'])\n","plt.title('Distribution of labels in dataset')\n","plt.xlabel('Distance [mm]')\n","plt.ylabel('n')\n","plt.legend()\n","plt.show()\n","\n","del mean, min, max, std\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## 3: Model\n","\n","### Create model\n","The model is created using `model/create_model.py`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from model.create_model import create_model\n","\n","model = create_model(dropout=0.2)"]},{"cell_type":"markdown","metadata":{},"source":["### Inspect model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Model training\n","The model is trained using `model_fit_model.py`\n","This should ideally be done using the workflow."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from model.fit_model import fit_model\n","\n","history = fit_model(model, x_train, y_train,\n","              optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'],\n","              epochs=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"Final loss: {history.history['loss'][-1]:.4f}\")\n","print(f\"Final accuracy: {history.history['accuracy'][-1]:.4f}\")\n","\n","# Trainings- und Validierungsverlust\n","plt.figure(1)\n","plt.plot(history.history['loss'], label='Training Loss')\n","if 'val_loss' in history.history:\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Loss per epoch')\n","plt.xlabel('Epopch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Genauigkeit (Accuracy) plotten\n","plt.figure(2)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","if 'val_accuracy' in history.history:\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Accuracy per Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluate model\n","The model is evaluated using `model/evaluate_model.py`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from model.evaluate_model import evaluate_model\n","\n","test_loss, test_acc = evaluate_model(model, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'Test accuracy: {test_acc:.4f}')\n","print(f'Test accuracy: {test_acc:.4f}')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Save model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save('model.keras')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":2}
